MongoDB
===========

Link Cartella Condivisa: https://docs.google.com/spreadsheets/d/1Ry-SryhwgquXXM8-fv19ADAv2xZ3ZqqB/edit?usp=share_link&ouid=100113145437900182221&rtpof=true&sd=true
Keys:
https://drive.google.com/file/d/1hCh26Kz7TTgOoi9CzWKCy-ILhBPabD2Q/view?usp=share_link


Install on Ubuntu

sudo apt update
sudo apt install openjdk-8-jdk
java -version
sudo apt install maven
mvn -v


https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-ubuntu/

cat /etc/issue
#wget -qO - https://www.mongodb.org/static/pgp/server-6.0.asc | sudo apt-key add -echo "deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/6.0 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-6.0.list
echo "deb [ arch=amd64,arm64 signed-by=/usr/share/keyrings/mongodb-server-6.0.gpg ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/6.0 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-6.0.list
sudo apt-get update
sudo apt-get install -y mongodb-org

sudo mkdir /data
sudo mkdir /data/db

On WSL2 cannot start as service:
sudo mongod&

======================

cd /home/azureuser
mkdir mongodb
cd mongodb
git clone https://github.com/thimotyb/mongodb-sample-dataset.git
cd mongodb-sample-dataset
mongoimport --drop --host localhost --port 27017 --db "sample_mflix" --collection movies --file sample_mflix/movies.json
mongoimport --drop --host localhost --port 27017 --db "sample_training" --collection companies --file sample_training/companies.json


========================
ACCESSING A COLLECTION / DOCUMENT

mongosh
show dbs
use sample_mflix
show collections
db.movies.findOne();

============================
Using like:
db.movies.find({ title: /Indiana Jones/}, {title: 1});
db.movies.find({title: "Indiana Jones and the Last Crusade"});
db.movies.updateOne({title: "Indiana Jones and the Last Crusade"}, {$set: {favorite: "yes"}});

========

movie = {"title" : "Star Wars: Episode IV - A New Hope",
 "director" : "George Lucas",
 "year" : 1977}

db.movies.insertOne(movie)
db.movies.find({ "title": "Star Wars: Episode IV - A New Hope"  });

db.movies.updateOne({ "title": "Star Wars: Episode IV - A New Hope"  }, { $set : { reviews: [ ] } } );
db.movies.deleteOne( { _id: ObjectId("6435245a8d425b6f1b65e86f")  } );  # Change _id

db.mymovies.insertOne({"title" : "Stand by Me"})

db.mymovies.insertMany([{"title" : "Ghostbusters"},
                        {"title" : "E.T."},
                        {"title" : "Blade Runner"}]);


===========================

Orered and Unordered Bulk Inserts

# Ordered Insert (does not complete on error)
db.mymovies.insertMany([
     {"_id" : 0, "title" : "Top Gun"},
     {"_id" : 1, "title" : "Back to the Future"},
     {"_id" : 1, "title" : "Gremlins"},
     {"_id" : 2, "title" : "Aliens"}])

# Unordered Insert (completes all valid records)
db.mymovies.insertMany([
 {"_id" : 3, "title" : "Sixteen Candles"},
 {"_id" : 4, "title" : "The Terminator"},
 {"_id" : 4, "title" : "The Princess Bride"},
 {"_id" : 5, "title" : "Scarface"}],
 {"ordered" : false})

# Deletes all documents!
db.mymovies.deleteMany({})
# Drop the entire collection
db.mymovies.drop()

===========================

REPLACE / UPDATEONE-UPDATEMANY / UPSERT

### Replace

person = {
    "_id" : ObjectId("4b2b9f67a1f631733d917a7a"),
    "name" : "joe",
    "friends" : 32,
    "enemies" : 2
}
db.users.insertOne(person)

var joe = db.users.findOne({ "name": "joe"  })
joe.relationships = {"friends" : joe.friends, "enemies" : joe.enemies};
joe.username = joe.name
delete joe.name
delete joe.enemies
delete joe.friends
# In the db still the old users structure, in var joe in memory, the new structure --> use replace to restructure using the new object
db.users.replaceOne({"name" : "joe"}, joe);

# What if we are working on multiple documents?
db.users.insertOne({"_id" : ObjectId("4b2b9f67a1f631733d917a7b"), "name" : "joe", "age" : 65})
db.users.insertOne({"_id" : ObjectId("4b2b9f67a1f631733d917a7c"), "name" : "joe", "age" : 20})
db.users.insertOne({"_id" : ObjectId("4b2b9f67a1f631733d917a7d"), "name" : "joe", "age" : 49})

joe = db.users.findOne({"name" : "joe", "age" : 20});
joe.age = joe.age+1

 db.users.replaceOne({"name":"joe"}, joe);
 db.users.replaceOne({"_id" : ObjectId("4b2b9f67a1f631733d917a7c")}, joe)


### Update operators:

pageview = {
    "_id" : ObjectId("4b253b067525f35f94b60a31"),
    "url" : "www.example.com",
    "pageviews" : 52
}

db.analytics.insertOne(pageview)

# Using increment atomic operator in update
db.analytics.updateOne({"url" : "www.example.com"}, {"$inc" : {"pageviews" : 1}})

# Showing update features for adding subdocuments
db.users.drop()
var user = {
    "_id" : ObjectId("4b253b067525f35f94b60a31"),
    "name" : "joe",
    "age" : 30,
    "sex" : "male",
    "location" : "Wisconsin"
}
db.users.insertOne(user)

db.users.updateOne({"_id" : ObjectId("4b253b067525f35f94b60a31")}, {"$set" : {"favorite book" : "War and Peace"}})
db.users.updateOne({"name" : "joe"}, {"$set" : {"favorite book" : "Green Eggs and Ham"}})

db.users.updateOne({"name" : "joe"}, {"$set" : {"favorite book" : ["Cat's Cradle", "Foundation Trilogy", "Ender's Game"]}})
db.users.updateOne({"name" : "joe"}, {"$unset" : {"favorite book" : 1}})

# Multi-dimensional insert
var post = {
    "_id" : ObjectId("4b253b067525f35f94b60a31"),
    "title" : "A Blog Post",
    "content" : "...",
    "author" : {
        "name" : "joe",
        "email" : "joe@example.com"
    }
}
db.posts.insertOne(post)

db.posts.updateOne({"author.name" : "joe"}, {"$set" : {"author.name" : "joe schmoe"}})

# This is not correct $set missing: db.posts.updateOne({"author.name" : "joe"}, {"author.name" : "joe schmoe"}) # WRONG!!! IT NEEDS UPDATE OPERATOR

# $inc as an upsert
db.games.insertOne({"game" : "pinball", "user" : "joe"})
db.games.updateOne({"game" : "pinball", "user" : "joe"}, {"$inc" : {"score" : 50}}) # field score does not exist, it is created
db.games.updateOne({"game" : "pinball", "user" : "joe"}, {"$inc" : {"score" : 10000}})
# Does not work on strings
db.strcounts.insertOne({"count" : "1"})
db.strcounts.updateMany({}, {"$inc" : {"count" : 1}})

# ARRAY MANIPULATION
db.posts.findOne()

db.posts.updateOne({"title" : "A Blog Post"},
 {"$push" : {"comments" :
     {"name" : "joe", "email" : "joe@example.com",
     "content" : "nice post."}}})

printjson(db.posts.findOne())
db.posts.updateOne({"title" : "A Blog Post"},
 {"$push" : {"comments" :
     {"name" : "bob", "email" : "bob@example.com",
     "content" : "good post."}}})
printjson(db.posts.findOne())

# Pushing multiple elements in one array with $each 
db.stocks.insertOne({"_id" : "GOOG"})
db.stocks.insertOne({"_id" : "DAN"})
db.stocks.updateOne({"_id" : "GOOG"}, {"$push" : {"hourly": 561.15}}) # Add the one by one
db.stocks.updateOne({"_id" : "GOOG"}, {"$push" : {"hourly": 561.16}})
db.stocks.updateOne({"_id" : "DAN"}, {"$set" : {"hourly": 561.16}})
# Or more than one with each
db.stocks.updateOne({"_id" : "GOOG"}, {"$push" : {"hourly" : {"$each" : [562.776, 562.790, 559.123]}}})
db.stocks.updateOne({"_id" : "DAN"}, {"$push" : {"hourly" : {"$each" : [562.776, 562.790, 559.123]}}})
# Not like this: db.stocks.updateOne({"_id" : "GOOG"}, {"$push" : {"hourly" : [562.776, 562.790, 559.123]}}) # Will add the array as a single element

# Deleting elements
db.lists.insertOne({"todo" : ["dishes", "laundry", "dry cleaning"]})
db.lists.updateOne({}, {"$pull" : {"todo" : "laundry"}}

# Positional array
db.stocks.updateOne({_id: "GOOG"}, {"$inc": { "hourly.0": 1 } })

# Slicing
db.stocks.updateOne({"_id" : "GOOG"}, {"$push" : {"hourly" : {"$each" : [562.776, 562.790, 559.123, 559.124, 559.125, 559.126], "$slice" : -10 }}})
# Sorting
db.stocks.updateOne({"_id" : "GOOG"}, {"$push" : {"hourly" : {"$each" : [562.776, 562.790, 559.123, 559.124, 559.125, 559.126], "$slice" : -10, "$sort" :  -1 }}})

# Treating arrays as Sets ($addToSet)
var user = {
    "_id" : ObjectId("4b2d75476cc613d5ee930164"),
    "username" : "joe",
    "emails" : [
        "joe@example.com",
        "joe@gmail.com",
        "joe@yahoo.com"
    ]
}
db.users.insertOne(user)
db.users.findOne({"_id" : ObjectId("4b2d75476cc613d5ee930164")})

db.users.updateOne({"_id" : ObjectId("4b2d75476cc613d5ee930164")}, {"$addToSet" : {"emails" : "joe@gmail.com"}}) # does not insert a new element (already present)
db.users.updateOne({"_id" : ObjectId("4b2d75476cc613d5ee930164")}, {"$addToSet" : {"emails" : "joe@hotmail.com"}})
db.users.updateOne({"_id" : ObjectId("4b2d75476cc613d5ee930164")}, {"$addToSet" : {"emails" : {"$each" : ["joe@php.net", "joe@example.com", "joe@python.org"]}}}) # each single element is evaluated for unicity

db.users.updateOne({"_id" : ObjectId("4b2d75476cc613d5ee930164")}, {"$pop" : {"emails" : 1} }) # 1 removes from the end of array, -1 from beginning

# POSITIONAL UPDATES ON ARRAYS

var posts = {
    "_id" : ObjectId("4b329a216cc613d5ee930192"),
    "content" : "...",
    "comments" : [
        {
            "comment" : "good post",
            "author" : "John",
            "votes" : 0
        },
        {
            "comment" : "i thought it was too short",
            "author" : "Claire",
            "votes" : 3
        },
        {
            "comment" : "free watches",
            "author" : "Alice",
            "votes" : -5
        },
        {
            "comment" : "vacation getaways",
            "author" : "Lynn",
            "votes" : -7
        }
    ]
}
db.posts.insertOne(posts)
db.posts.find()
db.posts.updateOne( {"_id" : ObjectId("4b329a216cc613d5ee930192")} , { "$inc" : { "comments.1.votes" : 1 }  } ) # Increment by position in array
db.posts.updateOne( {"comments.author" : "John"}, {"$set" : {"comments.$.author" : "Jim"}} ) # Positional operator

# CONDITIONAL ARRAY MANIPULATION

db.posts.updateOne( {"_id" : ObjectId("4b329a216cc613d5ee930192")}, { $set: { "comments.$[elem].hidden" : true } }, {
     arrayFilters: [ { "elem.votes": { $lte: -5 } } ]
   })


# UPSERT
db.analytics.find()
db.analytics.findOne({url : "/blog"})

################## LOGICAL UPSERT CODE (NOT ATOMIC!!!!!)
#// check if we have an entry for this page
#blog = db.analytics.findOne({url : "/blog"})
#// if we do, add one to the number of views and save
#if (blog) {
#  blog.pageviews++;
#  db.analytics.save(blog);
#}
#// otherwise, create a new document for this page
#else {
#  db.analytics.insertOne({url : "/blog", pageviews : 1})
#}
######################################

db.analytics.updateOne({"url" : "/blog"}, {"$inc" : {"pageviews" : 1}}, {"upsert" : true}) # ATOMIC READ AND INSERT IF NOT PRESENT
db.analytics.updateOne({"url" : "/blog"}, {"$inc" : {"pageviews" : 1}}, {"upsert" : true}) # READ AND INCREMENT (UPDATE)

=============================
READ

 db.movies.find({ title: /Indiana Jones/, runtime: 118 })
 db.movies.find({ title: /Indiana Jones/, runtime: 118 },{ title:1, year: 1 })

 db.movies.find({"runtime": { "$gte" : 120, "$lte" : 150 } })
 
 start = new Date("01/01/2000")
 db.movies.find({"released": { "$gt" : start } }, { title:1, released:1, _id:0 })

db.users.find()
db.users.find({"sex":{"$ne": "male"}})

####  db.posts.find({"title" : { "$in" : [ "My Adventure", "A Blog Post"]}}) ### CHECK THIS ONE

db.movies.find({"$or": [ {"year": 1943}, {"rated": "NOT RATED"} ]})

# QUERY ON ARRAYS

db.food.insertOne({"fruit" : ["apple", "banana", "peach"]})
db.food.find({"fruit" : "banana"}) # This matches the document!!!

# Using $all
db.food.insertOne({"_id" : 1, "fruit" : ["apple", "banana", "peach"]})
db.food.insertOne({"_id" : 2, "fruit" : ["apple", "kumquat", "orange"]})
db.food.insertOne({"_id" : 3, "fruit" : ["cherry", "banana", "apple"]})
db.food.find( {fruit: { $all: ["apple", "banana" ]  } } )

db.food.find( {fruit: ["apple", "banana", "peach" ] } ) # Array exact search
db.food.find( {fruit: ["apple", "banana" ]  } ) # This will not find anything

db.food.find( { "fruit.2": "peach" } ) # Positional search
db.food.find({"fruit" : { $size: 3 } } )

# Slicing on read
db.stocks.findOne({ _id: 'GOOG' }, {"hourly": { "$slice": 2 } }) # First two
db.stocks.findOne({ _id: 'GOOG' }, {"hourly": { "$slice": -2 } }) # Last two
db.stocks.findOne({ _id: 'GOOG' }, {"hourly": { "$slice": [1,4] } }) # Beginning from the second element for a total of four elements

# elemMatch

var post = {
    "content" : "...",
    "comments" : [
        {
            "author" : "joe",
            "score" : 3,
            "comment" : "nice post"
        },
        {
            "author" : "mary",
            "score" : 6,
            "comment" : "terrible post"
        }
    ]
}
db.posts.insertOne(post)

 db.posts.find({"comments" : {"author" : "joe", "score" : {"$gte" : 2}}}) # This will not work
 db.posts.find({"comments" : {"$elemMatch" : {"author" : "joe", "score" : {"$gte" : 2}}}})

Operators: https://www.mongodb.com/docs/manual/reference/operator/query/

=============================

Cursor:
for(i=0; i<100; i++) {
 db.mytest.insertOne({x : i});
}
var cursor = db.mytest.find();

cursor.forEach(function(j) {
    print(j.x*2);
 });
 
db.mytest.find().limit(5)
db.mytest.find().skip(3)
db.mytest.find().skip(3).limit(5)
db.mytest.find().skip(3).limit(5).sort({ "x": -1 }) # sorts first

=====================

INDEXES

for (i=0; i<1000000; i++) {
     db.users.insertOne(
         {
              "i" : i, 
              "username" : "user"+i,
              "age" : Math.floor(Math.random()*120), 
              "created" : new Date()
         }
     );
 }

db.users.find({"username": "user101"}).explain("executionStats")
db.users.find({"username": "user999999"}).explain("executionStats")
db.users.createIndex({"username" : 1})
db.users.find({"username": "user101"}).explain("executionStats")
db.users.find({"username": "user999999"}).explain("executionStats")
db.users.find().sort({"age" : 1, "username" : 1}) # Needs a compound index to workd
db.users.createIndex({"age" : 1, "username" : 1})
db.users.createIndex({"username" : 1, "age": 1})
db.users.find({}, {"_id" : 0, "i" : 0, "created" : 0})

db.users.find({"age" : {"$gte" : 21, "$lte" : 30}}).explain("executionStats") # uses the age key in the second index
db.users.find({"age" : {"$gte" : 21, "$lte" : 30}}).sort({"username" : 1}).explain("executionStats") # uses compound and then single index on username

db.users.find({"age" : {$gt : 10}, "username" : "user2134"}).explain() # uses username_1_age_1
db.users.find({"age" : 14, "username" : /.*/}).explain() # uses age_1_username_1

db.users.getIndexes()
db.users.dropIndex("username_1")

========================
GEOSPATIAL QUERIES
(on Atlas)
use sample_restaurants
db.neighborhoods.createIndex({geometry:"2dsphere"})
db.restaurants.createIndex({'address.coord':"2dsphere"})

db.neighborhoods.find({name: "Clinton"})
db.restaurants.find({name: "Little Pie Company"})
db.neighborhoods.findOne({geometry:{$geoIntersects:{$geometry:{type:"Point", coordinates:[-73.93414657,40.82302903]}}}})

var neighborhood = db.neighborhoods.findOne({
  geometry: {
    $geoIntersects: {
      $geometry: {
        type: "Point",
        coordinates: [-74.013222,40.70122]
      }
    }
  }
});

# Battery Park City-Lower Manhattan'
db.restaurants.find({'address.coord': {$geoWithin: { $centerSphere: [ [ -74.00972425205318, 40.70867294227663 ], 0.00018213153257553877 ]}}})

db.restaurants.find({
    'address.coord': {
      $geoWithin: {
        // Use the geometry from the neighborhood object we retrieved above
        $geometry: neighborhood.geometry
      }
    }
  },
  // Project just the name of each matching restaurant
  {name: 1, _id: 0});
  
// NEAR SPHERE
var METERS_PER_MILE = 1609.34;
db.restaurants.find({
  'address.coord': {
    $nearSphere: {
      $geometry: {
        type: "Point",
        coordinates: [-73.93414657,40.82302903]
      },
      $maxDistance: 5*METERS_PER_MILE
    }
  }
});

// FULL TEXT SEARCH

db.movies.getIndices();
db.movies.find({"$text": {"$search": "impact crater lunar"}}, {title:1}).limit(10)
db.movies.find({"$text": {"$search": "\impact crater\ lunar"}}, {title:1}).limit(10)
db.movies.find({"$text": {"$search": "\impact crater\ lunar"}}, {title:1, score: {$meta: "textScore"}}).sort({score: {$meta: "textScore"}}).limit(10)

// CAPPED COLLECTIONS
db.createCollection("my_collection", {"capped" : true, "size" : 100000});
// TTL INDEXES
// 24-hour timeout
db.sessions.createIndex({"lastUpdated" : 1}, {"expireAfterSeconds" : 60*60*24})

/////////////////////////
// AGGREGATION FW (on Atlas)
/////////////////////////
use sample_training
db.companies.findOne({"name": "Facebook"})
db.companies.aggregate([ {$match: {founded_year: 2004}}, ]) # same as db.companies.find({founded_year: 2004})

db.companies.aggregate([
  {$match: {founded_year: 2004}},
  {$project: {
    _id: 0,
    name: 1,
    founded_year: 1
  }}
])

db.companies.aggregate([
  {$match: {founded_year: 2004}},
  {$limit: 5},
  {$project: {
    _id: 0,
    name: 1}}
])

db.companies.aggregate([
    { $match: { founded_year: 2004 } },
    { $sort: { name: 1} },
    { $limit: 5 },
    { $project: {
        _id: 0,
        name: 1 } }
])

db.companies.aggregate([
  {$match: {founded_year: 2004}},
  {$sort: {name: 1}},
  {$skip: 10},
  {$limit: 5},
  {$project: {
    _id: 0,
    name: 1}},
])

db.companies.aggregate([
  {$match: {"funding_rounds.investments.financial_org.permalink": "greylock" }},
  {$project: {
    _id: 0, 
    name: 1,
    ipo: "$ipo.pub_year",
    valuation: "$ipo.valuation_amount",
    funders: "$funding_rounds.investments.financial_org.permalink"
  }}
]).pretty()

 // UNWIND
 db.companies.aggregate([
  {$match: {"funding_rounds.investments.financial_org.permalink": "greylock"} },
  {$project: {
    _id: 0,
    name: 1,
    amount: "$funding_rounds.raised_amount",
    year: "$funding_rounds.funded_year"
  }}
])

db.companies.aggregate([
  { $match: {"funding_rounds.investments.financial_org.permalink": "greylock"} },
  { $unwind: "$funding_rounds" },
  { $project: {
    _id: 0,
    name: 1,
    amount: "$funding_rounds.raised_amount",
    year: "$funding_rounds.funded_year"
  } }
])
 
# financial org needs to be filtered
db.companies.aggregate([
  { $match: {"funding_rounds.investments.financial_org.permalink": "greylock"} },
  { $unwind: "$funding_rounds" },
  { $project: {
    _id: 0,
    name: 1,
    funder: "$funding_rounds.investments.financial_org.permalink",
    amount: "$funding_rounds.raised_amount",
    year: "$funding_rounds.funded_year"
  } }
])

# Match after unwind to solve the problem
db.companies.aggregate([
  { $match: {"funding_rounds.investments.financial_org.permalink": "greylock"} },
  { $unwind: "$funding_rounds" },
  { $match: {"funding_rounds.investments.financial_org.permalink": "greylock"} },
  { $project: {
    _id: 0,
    name: 1,
    individualFunder: "$funding_rounds.investments.person.permalink",
    fundingOrganization: "$funding_rounds.investments.financial_org.permalink",
    amount: "$funding_rounds.raised_amount",
    year: "$funding_rounds.funded_year"
  } }
])

# Array expressions - Filtering
db.companies.aggregate([
  { $match: {"funding_rounds.investments.financial_org.permalink": "greylock"} },
  { $project: {
    _id: 0,
    name: 1,
    founded_year: 1,
    rounds: { $filter: {
      input: "$funding_rounds",
      as: "round",
      cond: { $gte: ["$$round.raised_amount", 100000000] } } }
  } },
  { $match: {"rounds.investments.financial_org.permalink": "greylock" } },
]).pretty()

# position ElemAt, Slice
db.companies.aggregate([
  { $match: { "founded_year": 2010 } },
  { $project: {
    _id: 0,
    name: 1,
    founded_year: 1,
    first_round: { $arrayElemAt: [ "$funding_rounds", 0 ] },
    last_round: { $arrayElemAt: [ "$funding_rounds", -1 ] }
  } },
  { $limit: 1}
]).pretty()

db.companies.aggregate([
  { $match: { "founded_year": 2010 } },
  { $project: {
    _id: 0,
    name: 1,
    founded_year: 1,
    early_rounds: { $slice: [ "$funding_rounds", 1, 3 ] }
  } },
  { $limit: 1}
]).pretty()

# ACCUMULATORS
db.companies.aggregate([
  { $match: { "funding_rounds": { $exists: true, $ne: [ ]} } },
  { $project: {
    _id: 0,
    name: 1,
    largest_round: { $max: "$funding_rounds.raised_amount" }
  } }
])

db.companies.aggregate([
  { $match: { "funding_rounds": { $exists: true, $ne: [ ]} } },
  { $project: {
    _id: 0,
    name: 1,
    total_funding: { $sum: "$funding_rounds.raised_amount" }
  } }
])

# GROUPING
db.companies.aggregate([
  { $group: {
    _id: { founded_year: "$founded_year" },
    average_number_of_employees: { $avg: "$number_of_employees" }
  } },
  { $sort: { average_number_of_employees: -1 } }

])

db.companies.aggregate( [
  { $match: { "relationships.person": { $ne: null } } },
  { $project: { relationships: 1, _id: 0 } },
  { $unwind: "$relationships" },
  { $group: {
    _id: "$relationships.person",
    count: { $sum: 1 }
  } },
  { $sort: { count: -1 } }
]).pretty()

# Using ID in Grouping
db.companies.aggregate([
  { $match: { founded_year: { $gte: 2010 } } },
  { $group: {
    _id: { founded_year: "$founded_year"},
    companies: { $push: "$name" }
  } },
  { $sort: { "_id.founded_year": 1 } }
]).pretty()

# Multiple fields in ID
db.companies.aggregate([
  { $match: { founded_year: { $gte: 2010 } } },
  { $group: {
    _id: { founded_year: "$founded_year", category_code: "$category_code" },
    companies: { $push: "$name" }
  } },
  { $sort: { "_id.founded_year": 1 } }
]).pretty()

# Composite ID used in following stages
db.companies.aggregate([
  { $group: {
    _id: { ipo_year: "$ipo.pub_year" },
    companies: { $push: "$name" }
  } },
  { $sort: { "_id.ipo_year": 1 } }
]).pretty()

# Writing aggregation results 

============================

CREATE LOCAL REPLICA SET

tmux
https://tmuxcheatsheet.com/

mkdir -p ~/data/rs{1,2,3}
sudo mongod --replSet rsExample --dbpath ~/data/rs1 --port 27017 --oplogSize 200
sudo mongod --replSet rsExample --dbpath ~/data/rs2 --port 27018 --oplogSize 200
sudo mongod --replSet rsExample --dbpath ~/data/rs3 --port 27019 --oplogSize 200
mongosh --port 27017

rsconf = {
    _id: "rsExample",
    members: [
      {_id: 0, host: "localhost:27017"},
      {_id: 1, host: "localhost:27018"},
      {_id: 2, host: "localhost:27019"} 
    ]
  }

rs.initiate(rsconf)
rs.status()

# Preferred Read and Write on Primaries
use test
for (i=0; i<1000; i++) {db.coll.insertOne({count: i})}
// make sure the docs are there
db.coll.countDocuments()
db.isMaster()
secondaryConn = new Mongo("localhost:27019")
secondaryDB = secondaryConn.getDB("test")
secondaryDB.coll.find() # this gives an error
# MongoServerError: not primary and secondaryOk=false - consider using db.getMongo().setReadPref() or readPreference in the connection string
secondaryConn.setReadPref('secondary')
secondaryDB.coll.insert({"count" : 1001}) # Error: can write only on primaries

# Automatic Failover
db.adminCommand({"shutdown" : 1}) # shutdown primary
secondaryDB.isMaster() # look at .primary and .me attributes
# restart ex-primary

rs.printReplicationInfo()
rs.printSecondaryReplicationInfo()

===============================

SINGLE NODE SHARD CREATION

https://www.mongodb.com/docs/manual/tutorial/deploy-shard-cluster/

mkdir -p ~/data/cfg{1,2,3}
mkdir -p ~/data/db{1,2,3}

sudo mongod --configsvr --replSet myReplSet --dbpath ~/data/cfg1 --port 27020
sudo mongod --configsvr --replSet myReplSet --dbpath ~/data/cfg2 --port 27021
sudo mongod --configsvr --replSet myReplSet --dbpath ~/data/cfg3 --port 27022

mongosh --port 27020

rs.initiate(
  {
    _id: "myReplSet",
    configsvr: true,
    members: [
      { _id : 0, host : "localhost:27020" },
      { _id : 1, host : "localhost:27021" },
      { _id : 2, host : "localhost:27022" }
    ]
  }
)

sudo mongod --shardsvr --replSet myReplShard  --dbpath ~/data/db1 --port 27017
sudo mongod --shardsvr --replSet myReplShard  --dbpath ~/data/db2 --port 27018
sudo mongod --shardsvr --replSet myReplShard  --dbpath ~/data/db3 --port 27019

mongosh --port 27017

rs.initiate(
  {
    _id : "myReplShard",
    members: [
      { _id : 0, host : "localhost:27017" },
      { _id : 1, host : "localhost:27018" },
      { _id : 2, host : "localhost:27019" }
    ]
  }
)

# start mongos router
sudo mongos --configdb myReplSet/localhost:27020,localhost:27021,localhost:27022 --port 27023
# connect to the shard router
mongosh --port 27023

# Operate on mongos mongo shell
sh.addShard( "myReplShard/localhost:27017,localhost:27018,localhost:27019")

# Shard a collection based on Hash or Range
#sh.shardCollection("<database>.<collection>", { <shard key field> : "hashed" } )
#sh.shardCollection("<database>.<collection>", { <shard key field> : 1, ... } )

use accounts
for (var i=0; i<100000; i++) {
     db.users.insertOne({"username" : "user"+i, "created_at" : new Date()});
}
db.users.findOne({username: 'user50000'})
db.users.countDocuments()
sh.status() # coll accounts not sharded yet (see: partitioned)
sh.enableSharding("accounts") # No longer needed since Mongo 6.0
db.users.createIndex({"username" : 1})
sh.shardCollection("accounts.users", {"username" : 1}, false,
  {
    numInitialChunks: 5,
    collation: { locale: "simple" }
  })
sh.status()

sh.balancerCollectionStatus("accounts.users")
sh.splitAt( "accounts.users", { "username": "user50000" } )
sh.status()

db.users.find({username: "user12345"}}).explain() # SINGLE SHARD QUERY PLAN

# Modify chunksize (experimental)
use config
db.settings.updateOne(
   { _id: "chunksize" },
   { $set: { _id: "chunksize", value: <sizeInMB> } },
   { upsert: true }
)


db.settings.updateOne(
   { _id: "chunksize" },
   { $set: { _id: "chunksize", value: 1 } },
   { upsert: true }
)

db.adminCommand( { balancerCollectionStatus: "accounts.users" } )


================

Reactive Mongo

mongodb+srv://m001-student:m001-mongodb-basics@cluster0.uuo3cgl.mongodb.net/test
https://github.com/thimotyb/spring-reactive-sample/tree/master/boot-data-mongo


